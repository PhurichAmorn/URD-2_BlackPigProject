{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX to TFLite Conversion using onnx2tf\n",
    "\n",
    "This notebook demonstrates converting an ONNX model to TFLite format using the modern `onnx2tf` tool.\n",
    "\n",
    "`onnx2tf` is specifically designed for ONNX → TFLite conversion and works with current TensorFlow versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Python version: 3.10.19 (main, Oct 14 2025, 21:43:20) [Clang 20.1.4 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys \n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Model Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found ONNX model at: segment_model.onnx\n"
     ]
    }
   ],
   "source": [
    "# Set path to your ONNX model\n",
    "onnx_path = 'segment_model.onnx'\n",
    "\n",
    "# Check that the file exists\n",
    "assert os.path.exists(onnx_path), f\"ONNX model not found at {onnx_path}\"\n",
    "print(f\"✓ Found ONNX model at: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert ONNX to TFLite\n",
    "\n",
    "The `onnx2tf` tool performs the conversion in a single step, going directly from ONNX to TFLite without intermediate formats.\n",
    "\n",
    "### Conversion Options:\n",
    "- `-i`: Input ONNX model path\n",
    "- `-o`: Output directory for converted model\n",
    "- `-osd`: Output SavedModel directory\n",
    "- `-coion`: Copy ONNX input order to output (maintains input shape compatibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/niner9/Documents/GitHub/URD-2_BlackPigProject/.venv/bin/onnx2tf\", line 3, in <module>\n",
      "    from onnx2tf import main\n",
      "  File \"/Users/niner9/Documents/GitHub/URD-2_BlackPigProject/.venv/lib/python3.10/site-packages/onnx2tf/__init__.py\", line 1, in <module>\n",
      "    from onnx2tf.onnx2tf import convert, main\n",
      "  File \"/Users/niner9/Documents/GitHub/URD-2_BlackPigProject/.venv/lib/python3.10/site-packages/onnx2tf/onnx2tf.py\", line 29, in <module>\n",
      "    import tf_keras\n",
      "ModuleNotFoundError: No module named 'tf_keras'\n"
     ]
    }
   ],
   "source": [
    "# Run onnx2tf conversion\n",
    "!onnx2tf -i segment_model.onnx -o saved_model -osd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verify Output Files\n",
    "\n",
    "The conversion should produce:\n",
    "- `saved_model/` directory with SavedModel format\n",
    "- `saved_model/model_float32.tflite` - the TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output files\n",
    "output_dir = 'saved_model'\n",
    "tflite_path = os.path.join(output_dir, 'model_float32.tflite')\n",
    "\n",
    "if os.path.exists(tflite_path):\n",
    "    file_size = os.path.getsize(tflite_path) / (1024 * 1024)  # Convert to MB\n",
    "    print(f\"✓ TFLite model created successfully!\")\n",
    "    print(f\"  Path: {tflite_path}\")\n",
    "    print(f\"  Size: {file_size:.2f} MB\")\n",
    "else:\n",
    "    print(f\"✗ TFLite model not found at {tflite_path}\")\n",
    "\n",
    "# List all files in output directory\n",
    "print(\"\\nOutput directory contents:\")\n",
    "for root, dirs, files in os.walk(output_dir):\n",
    "    level = root.replace(output_dir, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f\"{subindent}{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspect TFLite Model Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model and inspect its details\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"=== Input Details ===\")\n",
    "for i, detail in enumerate(input_details):\n",
    "    print(f\"\\nInput {i}:\")\n",
    "    print(f\"  Name: {detail['name']}\")\n",
    "    print(f\"  Shape: {detail['shape']}\")\n",
    "    print(f\"  Data type: {detail['dtype']}\")\n",
    "\n",
    "print(\"\\n=== Output Details ===\")\n",
    "for i, detail in enumerate(output_details):\n",
    "    print(f\"\\nOutput {i}:\")\n",
    "    print(f\"  Name: {detail['name']}\")\n",
    "    print(f\"  Shape: {detail['shape']}\")\n",
    "    print(f\"  Data type: {detail['dtype']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Inference (Optional)\n",
    "\n",
    "Run a simple test inference to verify the model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input data based on the model's expected input shape\n",
    "input_shape = input_details[0]['shape']\n",
    "input_dtype = input_details[0]['dtype']\n",
    "\n",
    "print(f\"Creating test input with shape: {input_shape}, dtype: {input_dtype}\")\n",
    "\n",
    "# Generate random test data\n",
    "test_input = np.random.randn(*input_shape).astype(input_dtype)\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(f\"\\n✓ Inference successful!\")\n",
    "print(f\"  Output shape: {output_data.shape}\")\n",
    "print(f\"  Output dtype: {output_data.dtype}\")\n",
    "print(f\"  Output range: [{output_data.min():.4f}, {output_data.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Copy TFLite Model to Root Directory (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Copy the TFLite model to a more accessible location\n",
    "output_tflite_path = 'segment_model.tflite'\n",
    "shutil.copy(tflite_path, output_tflite_path)\n",
    "\n",
    "print(f\"✓ TFLite model copied to: {output_tflite_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook successfully converted an ONNX model to TFLite format using `onnx2tf`.\n",
    "\n",
    "The resulting TFLite model can be deployed on:\n",
    "- Android devices\n",
    "- iOS devices\n",
    "- Embedded systems\n",
    "- Edge devices\n",
    "\n",
    "### Next Steps:\n",
    "1. Optimize the model further (quantization, pruning)\n",
    "2. Integrate into your mobile application\n",
    "3. Benchmark performance on target device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
